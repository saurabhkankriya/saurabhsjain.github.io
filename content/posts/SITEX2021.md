---
title: "Reflections from SITEX 2021"
date: 2021-06-26T10:55:43+05:30
description: lessons learnt 
menu:
  sidebar:
    name: Reflections from SITEX 2021
    identifier: SITEX2021
    weight: 10
---

SITEX stands for SIEMENS Innovation and Technology Exchange. Its a program which focuses on developing PoC around strategically identified Technologies. Employees around the globe participate, form teams and pitch their usecase to the jury which comprises of Heads of several departments. So this is a huge event with a lot of visibility.  The technologies identified for the year 2021 were: 
- Mendix
- Edge Computing
- Computer Vision
- Demand Forecasting
- Hololayer
- Industrial 5G

I was part of Computer Vision team. We created a PoC around developing image classification which could identify defective products for factories. We used Google's AutoML vision for developing the solution. We couldnt make it to the pole positions. 

Here are some of the reflections:

1. **Innovation is key:** The use-case we selected was implemented by last year's winning Computer Vision Team. Honestly, I feel our use-case was pretty much inspired by what the time had already done and the jury was not impressed with it.

2. **Spend time researching the use-case**: There were plenty of use-cases from which we could have made the selection but we lacked the research. 

3. **Novelty + Business impact**: Modern problems require model solutions. What has already been implemented may not work for other scenarios. The Business wants to harness new tech to address their most demanding problem.  

4. **Scalability**: Our solution was not scalable to thousands of other products as it was trained only on one product. The solution you develop should either address one specific problem or be good enough to scale well across the category.

5. **Pracitcal implications of the use-case**: We didnt think through the practical limitations like how the livefeed would be fed into the CV app, security constraints of using other cloud providers, the re-training of the model etc. 

6. **Dataset**: Given the Covid situation it was not possible to get the real data from the factory. Also, the data we asked the business was not enough in volume to be fed to the training model.   

7. **The Pitch**: We delivered the pitch nicely and within time. I think where we lost most the points was in the question round. We were explaining the answers a bit more in detail whereas the answers expected should have brief and succint. Pitch is the most vital part of any use-case. I would weigh 80:20 ratio for pitch to demo. 

8. **The meeting with Business**: We should have met every week with the business to track progress, iterate and improve based on the feedback. Due to our diverse team, project committments and leaves due to Covid, we could not schedule more meetings with the Business.

9. **Asking questions to the coach**: We did not leverage the adavantage of our coach to the maximum. Our questions primarily focussed on the technical part and less on the business impact, pitch and other things. Our coach was very helpful but we failed to utilize his experience to our benefit.

10. **More iterations lead to improvements**: We did dry runs of our presentation with the organizers. The feedback from them was very valuable. Mimicing real scenarios and working in those situations can 10x improve your work. 

The good thing is I am not discouraged and I have taken the responsibilty of leading Computer Vision guild to do even better. New opportunities ahead definitely. Failing often teaches you something and makes you somewhat philosophical:  

`Failing is OK; it lets you fall, make you learn how to stand-up again, iterate and improve. What is not OK, is getting discouraged and quitting.` 



